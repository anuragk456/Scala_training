{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Do Following Spark jobs using Scala\n",
    "on Local Mode using only RDDs\n",
    "\n",
    "1. Given a collection of strings, write a Spark program to count the total number of words in the collection using RDD transformations and actions.\n",
    "\n",
    "2. Create two RDDs containing numbers and write a Spark program to compute their Cartesian product using RDD transformations.\n",
    "\n",
    "3. Create an RDD from a list of integers and filter out all even numbers using a Spark program.\n",
    "\n",
    "4. Write a Spark program to count the frequency of each character in a given collection of strings using RDD transformations.\n",
    "\n",
    "5. Create an RDD from a list of tuples `(id, score)` and write a Spark program to calculate the average score for all records.\n",
    "\n",
    "6. Create two RDDs containing key-value pairs `(id, name)` and `(id, score)`. Write a Spark program to join these RDDs on `id` and produce `(id, name, score)`.\n",
    "\n",
    "7. Write a Spark program to perform a union operation on two RDDs of integers and remove duplicate elements from the resulting RDD.\n",
    "\n",
    "8. Create an RDD from a list of strings where each string represents a CSV row. Write a Spark program to parse the rows and filter out records where the age is less than 18.\n",
    "\n",
    "9. Create an RDD of integers from 1 to 100 and write a Spark program to compute their sum using an RDD action.\n",
    "\n",
    "10. Write a Spark program to group an RDD of key-value pairs `(key, value)` by key and compute the sum of values for each key.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
